<div align="center">
<h1>Dark Matter, Public Health, and Scientific Computing</h1>
<h2>Dr. Greg Wilson<br/><a href="http://software-carpentry.org">Software Carpentry</a></h2>
</div>
<blockquote><em>
<div align="center"><strong>Abstract</strong></div>
Scott Hanselman coined the term "dark matter developers" to refer to the 99% of programmers who don't blog, don't attend conferences, and don't post questions on Stack Overflow, but instead just get things done. This talk will look at the dark matter of computational science&mdash;those researchers who won't or can't use today's e-science tools&mdash;and at what we should be doing to help them.</em>
</blockquote>
<p>Back in March, <a href="http://www.hanselman.com/blog/AboutMe.aspx">Scott Hanselman</a> wrote a blog post titled <a href="http://www.hanselman.com/blog/DarkMatterDevelopersTheUnseen99.aspx">Dark Matter Developers: The Unseen 99%</a> that crystallized a lot of my thinking. In it, he said:</p>
<blockquote><em>[We] hypothesize that there is another kind of developer than the ones we meet all the time. We call them Dark Matter Developers. They don't read a lot of blogs, they never write blogs, they don't go to user groups, they don't tweet or facebook, and you don't often see them at large conferences... [A]s one of the loud-online-pushing-things-forward 1%, I might think I need to find these Dark Matter Developers and explain to them how they need to get online! Join the community! Get a blog, start changing stuff, mix it up! But...those dark matter 99% have a lot to teach us about GETTING STUFF DONE... They aren't chasing the latest beta or pushing any limits, they are just producing.</em></blockquote>
<p>I'm not as optimistic as Scott, at least, not when it comes to scientific computing. I agree that 95% spend their time with their heads down, working hard, instead of talking about using GPU clouds to personalize collaborative management of reproducible peta-scale workflows, or some other permutation of currently-fashionable buzzwords. It isn't even because they don't know there's a better way. It's because for them, that better way is out of their reach.</em>
<p>Let me back up a few years. In 1997, while I was on holiday in Venezuela, that country took delivery of its first CT scanner. It was the lead story on the evening news, complete with a few seconds of video showing a military convoy escorting the device to the university hospital. Why a military convoy? Because to get from the airport to the center of the city, the truck carrying the scanner had to pass through a slum where three quarters of a million people didn't have clean water, much less first-world health care.</p>
<p>That image has stuck in my head ever since because it's the most accurate summary of the state of scientific computing that I know. While you are here talking about the CT scanners of computational science, the 95% (and yes, I do think it <em>is</em> 95%) are suffering from computational dysentery. If you think I'm exaggerating, ask yourself:</p>
<ol>
  <li>How many graduate students in numerate disciplines at the university nearest you write shell scripts to analyze data sets in batches instead of running those analyses manually?</li>
  <li>How many faculty at that university use version control to keep track of what they've done and collaborate with colleagues? (In the largest computer science department in Canada, the answer is only 10%.)</li>
  <li>How many of them routinely and instinctively break large computational problems down into pieces small enough to be comprehensible, testable, and reusable? For bonus marks, how many of them know those are really all the same thing?</li>
</ol>
<p>Now, you could say this isn't your problem, but you'd be wrong: it's actually the biggest problem you have. Why? Because if people are chronically malnourished, giving them access to a CT scanner when they're in their twenties doesn't make a damn bit of difference to their well being.</p>
<p>At this point I'm going to say something which I can't back up with hard data, but which I believe is true. I think all of you believe it too, though you may not want to admit it. My claim is that if you set aside googling for things, the overwhelming majority of graduate students in science today don't use computers any more effectively than students in my generation did twenty-five years ago. Today's students are no more likely to know that routine tasks can be automated; they're no more likely to understand the difference between structured and unstructured data, and it takes them just as long to write a 300-line data analysis script as it did when people would actually get a little giddy at the thought of having a 16 megahertz Sun-3 workstation with 8 megabytes of RAM on their desk.</p>
<p>So why is that your problem? Morally, because you're only helping the 1% of scientists who are lucky enough to have acquired the base skills they need to take advantage of the opportunities you're offering. But appeals to morality rarely change the world, so I'm going to appeal to your self-interest. Because those basic skills are missing, your potential user base is many times smaller than it could be. Putting it another way, a lot of scientists who could go to bat for your project and its funding aren't doing so.</p>
<p>Let's pause for a moment and fill in some details. First, is it true that only a few percent of research scientists are computationally competent? As I said, I don't have data to put in front of you, but I've been helping scientists of all kinds do computational work since 1986, not just at supercomputing centers. Working in those gives you a biased view of the world, just like working in the CT lab at a third-world hospital whose patients can all afford first-world health care gives you a biased view of how the general population is doing. And I've been teaching scientists at universities and government labs as a full-time job for most of the last two and a half years, and talking to a wide variety of people who are doing the same thing. One percent would be pessimistic hyperbole, but there's no way the actual number is more than five percent.</p>
<p>Second, what do I actually mean by "computationally competent"? We've all heard of "computational thinking", but that phrase has been completely devalued by people jumping on a bandwagon without actually changing direction. When I say that someone is computationally competent, I mean the same thing I mean when I say they're statistically competent: they know enough to do routine tasks without breaking a sweat, where to look to find answers they can understand to harder problems, and when to go and find an expert to solve their problems for them. More specifically, I think a scientist is computationally competent if she knows how to build, use, validate, and share software to:</p>
<ol>
  <li>manage data,</li>
  <li>process it,</li>
  <li>tell if she's processed it correctly,</li>
  <li>find and fix bugs when she hasn't,</li>
  <li>keep track of what she's done,</li>
  <li>find and use other people's work, and</li>
  <li>do all of the above quickly and without superhuman effort.</li>
</ol>
<p>You can't do these things without understanding some fundamental concepts&mdash;that's what "computational thinking" would mean if it still meant anything. But mastering those concepts is intrinsically dependent on mastering the tools used to put them into practice: you cannot use tools effectively you're working by rote, but equally, you cannot grasp abstractions without concrete examples to hang on to.</p>
<p>Are you computationally competent? Let's find out. Please grab a pen and a piece of paper, or shut down Facebook and open an editor instead. I'm going to show an outline of the "driver's license" exam we put together for physicists who want to use the new DiRAC supercomputing facility. I won't ask you to actually answer the questions; instead, I'll show you what you need to do in order to get full marks. For each step, I'd like you to give yourself one point if you're sure you could it, half a point if you think you might come up with a solution after some struggle, zero if you're sure you couldn't, and -1 if you don't understand what it says. Ready? Here goes.</p>
<p><strong>Question 1</strong>: Check out a working copy of the examination materials from Subversion.</p>
<p><strong>Question 2</strong>: Use <code>find</code> and <code>grep</code> together in a single command to create a list of all <code>.dat</code> files in the working copy, and redirect the output to create a file called <code>all-dat-files.txt</code>, then commit that file to the repository.</p>
<p><strong>Question 3</strong>: Write a shell script that takes one or more numbers as command-line parameters and runs a legacy Python program once for each number.</p>
<p><strong>Question 4</strong>: Edit a Makefile so that if any <code>.dat</code> file in the input directory changes, the program <code>analyze.py</code> is run to create a corresponding <code>.out</code> file.</p>
<p><strong>Question 5</strong>: Write four tests using an xUnit-style unit testing framework for a function that calculates running totals. Explain why you think your four tests are the most likely to uncover bugs in the function.</p>
<p><strong>Question 6</strong>: Explain when and how the function that calculates running totals might still produce wrong answers, even though it passes your tests.</p>
<p><strong>Question 7</strong>: Do a code review of the legacy program used in Question 3 (which is about 50 lines long) and describe the four most important improvements you would make to it.</p>
<p>How many of you think you'd get 7 out of 7? How many would get at least a 5? How many had positive scores? Really? If we give this test to 100 randomly-selected faculty and grad students from science and engineering departments in this country, the median score will be somewhere around 2.</p>
<p>Do you think that someone could use that GPU provenance peta-cloud <em>without</em> knowing how to do the things this test assesses? More importantly, do you think that someone who doesn't have these skills, and doesn't understanding the concepts they embody, will be able to think of new ways to use that peta-cloud to advance their research? Because the real point isn't to give scientists a handful of tools&mdash;the real point is to give them what they need to build tools for themselves.</p>
<p>And before we go on: the point of the exam isn't the specific tools. We could use Git instead of Subversion, or MATLAB instead of Python, and in fact, we're preparing variants of the exam to do exactly that. Ten years from now, the exam might allow for direct neural interfaces, but the core ideas of automating repetitive tasks and being table to tell good code from bad will, I think, remain the same.</p>
<p>All right: now that we've diagnosed the problem, the cure seems obvious. All we have to do is get universities to put more computing in their undergrad programs. However, we've been banging that drum for at least twenty-five years now, with no real success. Yes, there are a few programs in physics and computing or bioinformatics, but having worked with a few of their graduates, I don't think those programs do any better than the "soak it up by osmosis in grad school" approach. The problem is that everyone's curriculum is already full to bursting. If we want to put more computing into a four-year undergrad program in chemistry, we have to drop&mdash;what? Thermodynamics, or quantum mechanics? And please don't pretend that we can just put a bit into every course. Number one, five minutes out of every lecture hour adds up to four courses over the span of a degree. Second, those five minutes will be the first thing dropped when the lecturer is running late. And third, are you familiar with the phrase "the blind leading the blind"?</p>
<p>Here are a few other things that haven't worked:</p>
<ul>
  <li><strong>Weekly non-credit seminars.</strong>  Just like putting a few minutes of computing in every undergrad lecturer, it's what gets squeezed out when other deadlines are looming, and once again, it's all too often a case of the blind leading the blind.</li>
  <li><strong>Asking computer science departments for help.</strong>  Academic computer scientists are driven by the same "publish or perish" imperative as their peers in other departments. Simply put, teaching things that have worked well for years&mdash;i.e., that are no longer publishable&mdash;isn't going to pique their interest.</li>
  <li><strong>Recorded video lectures</strong> and robo-graded programming exercises. People who study education&mdash;a set that doesn't include most university instructors, including my younger-by-two-years self&mdash;know that this is ineffective, even if cost-cutting politicians, their profit-hungry allies on Wall Street, and a bunch of navel-gazing nerds living in the great echo chamber that is Silicon Valley would like to pretend otherwise.</li>
</ul>
<p>The only thing that <em>does</em> work&mdash;at least, the only thing that has worked for us in fourteen years of experimentation&mdash;is to give graduate students a few days of intensive training in practical skills followed by a few weeks of slower-paced instruction. Let's break that down:</p>
<ul>
  <li>Target <strong>graduate students</strong> students because they have an immediate personal need (particularly if they're six months or a year into their research and have realized just how painful it's going to be to brute force their way to a solution), and because they have time (which faculty usually don't).</li>
  <li>Teach them for <strong>a few days of intensive training</strong> because that's what they can actually schedule. At the low end, Software Carpentry's workshops are two days long (three if the host adds a day of discipline-specific material at the end). At the high end, Titus Brown's Next Generation Sequencing course at Michigan State runs for two weeks, which means there's time for volleyball and beer. Anything less than two days, and you can't cover enough to make it worthwhile. Anything more than two weeks, and people can't put the rest of their lives aside to attend.</li>
  <li>Focus on <strong>practical skills</strong> so that they see benefits immediately. That way, when we come to them and say, "Here's something that's going to take a little longer to pay off," they're more likely to trust us enough to invest the required time.</li>
  <li>Follow up with <strong>a few weeks of slower-paced instruction</strong>, such as meeting once a week for an hour to work through a few problems. We've tried doing this with online video conferencing, and while that's better than nothing, it's like old dishwater compared to the hearty organic beer of sitting side by side.</li>
</ul>
<p>What do we actually teach? It depends on the audience, but our core is:</p>
<ul>
  <li><strong>The Unix shell.</strong>  We only cover a dozen basic commands; our real aim is to introduce people to pipes, loops, history, and the idea of scripting.</li>
  <li><strong>Python.</strong>  Here, our goal is to show them how to build components for use in pipelines (so that they'll see there's no magic), and when and why to break code into functions.</li>
  <li><strong>Version control,</strong> for collaboration and reproducibility.</li>
  <li><strong>Testing.</strong>  We teach them to use tests to specify behavior and make refactoring safe as well as to check correctness.</li>
</ul>
<p>We usually include one other topic as well: a quick intro to SQL, matrix programming, or something more exotic. It may not sound like much, but two independent assessments have found that it's enough to set between a third and a half of scientists on the road that leads to those reproducible peta-scale GPU cloud workflows I mentioned earlier. Even if you take the lower of those two figures, that's a six-fold increase in the number of people who understand what you're trying to do, and are able to take advantage of it. If you think that's not going to help your project, you're either incredibly arrogant, hopelessly naive, independently wealthy, or a die-hard Lisp programmer.</p>
<p>So there you have it. If you want what you're doing to move into the mainstream, you have to create an audience for it. Offering a course on MPI in C++ isn't going to grow your user base; it will only actually reach people who would figure it out on their own anyway. What you need to do instead is help people get people from A to B so that you can then get to C, D, M, Z, &theta;, &#x263A;, and beyond. You can't teach calculus to people who don't know what a polynomial is; why should you expect that people who don't understand how a call stack works will understand, value, fund, and most importantly, <em>use</em> the things people talk about at an <a href="http://www.ci.uchicago.edu/escience2012/">eScience conference</a>?</p>
<p>Anatole France once wrote, "The law, in its majestic equality, forbids the rich and the poor alike to sleep under bridges, to beg in the streets, and to steal bread."  Today, low-cost clusters, the web, and e-science allow both scientists who don't know what a call stack is <em>and</em> those who mess around with web services to share reproducible workflows on peta-scale GPU something-or-others. A few months shy of my fiftieth birthday, with a wonderful little girl at home who's going to inherit all the problems we didn't get around to solving, and my sister eight months dead from cancer, I'd rather be making a real difference than promising the same old salvation to the same old crowd. I would rather double the productivity of 90% of scientists than increase the output of a small minority ten-fold. I would rather spend ten dollars a head bringing clean drinking water to a million people than ten million dollars on a shiny toy that none of them will ever even see.</p>
<p>You can help. In fact, we can't succeed <em>without</em> your help. The first and most important thing is to run workshops wherever you are. All of our materials are open license: you can use them whenever and however you want to teach scientists things that will have an immediate, dramatic impact on their lives. They will thank you for this, and when you then go back to them and say, "Here's this other thing I've been working on," they won't just be ready for it&mdash;they'll be willing to trust you even if their first few attempts to use it are frustrating.</p>
<p>If you don't want to run a workshop yourself, you can help by hosting one. A growing number of our alumni have become instructors in their own right&mdash;there are even a few here in the audience today. They're all volunteers, so the only cost is a couple of plane tickets, a couple of hotel rooms, and a few pots of coffee. If you're willing to book a room and do some advertising, we can send people to you to get things started. This will particularly help those of you in support roles: the people who've been through workshops probably won't ask fewer questions, but they'll certainly ask better ones.</p>
<p>Finally, you can help shine some light on the "dark matter" of scientific computing. There's a lot of discussion now about requiring scientists to share their software. What I'd like even more is for scientists to share their computational practices. I'd like every paper I review to include a few lines telling me where the version control repository holding the code is, what percentage of the code is exercised by unit tests, whether the analyses we're being shown were automated or done by hand, and so on. I'm not suggesting that we should require people to meet any particular targets&mdash;not yet, anyway&mdash;but the first step in any public health campaign has to be finding out how many people are sick with what.</p>
<p>I would rather raise up a generation of scientists who can <em>all</em> do what we're excited about doing than come back here in ten years and see what I see today: a community whose membership changes, but whose numbers do not grow. If you'd like to help, please visit our web site at <a href="http://software-carpentry.org">http://software-carpentry.org</a> or mail us at <a href="mailto:info@software-carpentry.org">info@software-carpentry.org</a>. We look forward to hearing from you.</p>
